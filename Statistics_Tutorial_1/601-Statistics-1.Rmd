---
title: 'Statistics Tutorial 1 - Categorical Data'
output: learnr::tutorial
runtime: shiny_prerendered
---
```{r setup, include=FALSE}
library(learnr)
library(tidyverse)
library(knitr)
opts_chunk$set(echo = TRUE)
tutorial_options(exercise.timelimit = 10)
```

## **Introduction**

In this tutorial, you will learn about categorical data - when our measurements aren't represented as quantities but as different subsets of a category. 

We will learn the following R Commands:

* `table()`
* `prop.table()`
* `pchisq()`
* `chisq.test()`
* `fisher.test()`

And we will use the following datasets:
  
* A simulated dataset: **sample_poly_data**  
* Motor Trend Car Road Tests: **mtcars**
 
## **Categorical Data**
  
We call our data **categorical** if it cannot be rank-ordered. By that we mean that responses cannot be ordered based on greater/lesser presence of a quantity. For example, say we ask respondents to a survey to give their political affiliation as Republican, Democrat, or Independent. These are qualitative values, so we have to treat them as categories. This is also called **nominal** data.
  
You may even have a dataset where a categorical variable has values coded as numbers. For example, a researcher may have coded responses to the "political affiliation" question with numbers: 1 for Republican, 2 for Democrat, and 3 for Independent.
  
```{r echo=FALSE}
set.seed(601)
sample_data <- tibble(
  political_affiliation = sample(c(1:3),60,replace = T)
)
```
  
Here's some (fake) data illustrating this example.
```{r}
# (hypothetical) dataset
# political_affiliation indicates their political affiliation, where 1=republican, 2=democrat, 3=independent
sample_data
```
  
Despite the fact that 1, 2, and 3 are numbers, they don't represent quantities of `political_affiliation`. They are merely qualitative labels. A respondent with a `political_affiliation` value of 2 does not have "more" political affiliation than a respondent with a `political_affiliation` value of 1. Thus, it would not make sense to treat `political_affiliation` the same way we would a numerical variable (e.g., age, income). So we will use a tool called a **frequency table** to summarize these data.
  
### **Frequency tables**
  
A frequency table counts the *frequency* with which each individual value occurs. This is called **tabulation**. Let's use a simulated dataset of republicans, democrats, and independents (for ease of visualization, the numerical values are changed to words). 
  
```{r echo=F}
set.seed(603)
sample_poly_data <- tibble(
  political_affiliation = sample(c('republican','democrat','independent'),size = 100,replace = TRUE, prob=c(.45,.45,.1))
)
```  

```{r}
# Sample data
sample_poly_data
```
  
These data are not very helpful in their current format. We need to find out how many Republicans, Democrats, and Independents are in our sample. In other words, we want to see how this variable is *distributed*.   
  
We can tabulate all unique values using R's `table()` function. 
  
```{r}
# using the table function to get 1d frequency table - base R method
table(sample_poly_data)

# using the table function to get 1d frequency table - tidyverse method
freq_table_poly <- sample_poly_data %>%
  table()
freq_table_poly
```

This summarizes our data nicely, we can see that our sample contains `r freq_table_poly['republican']` Republicans, `r freq_table_poly['democrat']` Democrats, and `r freq_table_poly['independent']` Independents. 
  
### **Relative Frequency Tables**
  
We can also compute a **relative frequency table**, which computes how often each value occurs compared to other values. Essentially, this gives us proportions for each value.  
  
We can do this using R's `prop.table()` function. We can simply pass `freq_table_poly` to this function.
  
```{r}
# using the table function to get 1d frequency table - base R method
prop.table(freq_table_poly)

# using the table function to get 1d rel. frequency table - tidyverse method
prop_table_poly <- freq_table_poly %>%
  prop.table()
prop_table_poly
```
  
This tells us that in our sample, Independents are relatively infrequent compared to Republicans and Democrats, making up only `r 100*prop_table_poly['independent']`% of the sample.

### **Exercise 1**

Using the dataset `mtcars`, compute a one-way frequency table from the variable `vs` (engine shape), saving it as an object. Then compute a relative frequency table from that object, using the function `prop.table()`. Also try doing it with and without pipes.
  
```{r}
# Quick look at the data.
head(mtcars)
```
  
```{r one-way-freq-table, exercise=TRUE}
# Compute freq table with mtcars$vs

```

```{r one-way-freq-table-solution}
# tidyverse method
freq_tab <- mtcars %>%
  select(vs) %>%
  table()
freq_tab
freq_tab %>%
  prop.table()

# base R method
freq_tab_2 <- table(mtcars$vs)
freq_tab_2
prop.table(freq_tab_2)
```
  
## **Null Hypothesis Significance Testing**
  
### **Chi-Square Goodness of Fit**
  
```{r}
# Examining our 1d frequency table again
freq_table_poly
```
  
Looking at our frequency table, it looks like people are slightly less likely to be Independents than they are to be Republicans or Democrats. We can think about this in terms of probabilities. If there was an "even split" between Republicans, Democrats, and Independents, ~33% of our sample would be Republicans, ~33% would be Democrats, and ~33% would be Independent, because $100\% / 3 = 33.33\%$. However, this does not appear to be the case with our sample.  
  
We can use this principle to calculate the frequencies we would expect to observe in our sample, Republicans, Democrats, and Independents were equally common in our sample.
  
To figure this out, we first find the number of people in our sample.  
  
```{r}
# use the nrow() function to get number of rows in the df (i.e., sample size)
sample_size <- nrow(sample_poly_data)
```
  
Then, we multiply `sample_size` by the proportion of each category we would expect **IF** Republicans, Democrats, and Independents were equally common in our sample.   
  
```{r}
# because there are 3 categories. 
prob <- rep(1/3,3) 
# expected frequency for a cell = sample size * probability
expected <- sample_size*prob 
# naming each category
names(expected) <- c('democrat', 'independent', 'republican') 
expected 
freq_table_poly
```
  
When we compare `expected` (the counts we would **expect** if Republicans, Democrats, and Independents were equally common in our sample) to our `freq_table_poly` (the frequencies of Republicans, Democrats, and we actually **observed**), there are clearly some discrepancies. Independents are far less common than Republicans or Democrats.
  
Because the reason we study a sample is that we want to learn something about the **population** the sample comes from, we have to ask ourselves - do these data actually allow us to infer that Independents are less common than Republicans/Democrats in the population? In other words, what is the probability that we would have observed these data (or data more extreme) if all political parties were equally common in the population?
  
It turns out there's a statistical test that can give us that information, called the **Chi-Square Goodness of Fit**. The Chi-Square statistic is computed as following.
$$\chi^{2}=\sum_{i=1}^{N} \frac{(O_{i}-E{i})^{2}}{E_{i}}$$
  
Where $i$ is used to index the group (e.g., Democrat, Republican, or Independent), $N$ refers to the total number of categories (3 in this case), $O_{i}$ is the observed counts for a category, and $E_{i}$ is the expected counts for a category. 
  
Before we actually calculate this statistic, we will first define the **Null and Alternative Hypotheses**. 
  
The **null hypothesis** is the hypothesis of **no difference** between groups (generally speaking). We start by assuming the null is true and then determine whether or not there is evidence against it through the results of our test. In our case, the null hypothesis is that all political affiliations are equally likely in the population. We can write this as:  
  
$H0: P_{Republican} = P_{Democrat} = P_{Independent}$  
That is, all probabilities are equal. Statisticians commonly use $H0$ to refer to the null hypothesis and $HA$ to refer to the alternative hypothesis.
  
The **alternative hypothesis** is often our research hypothesis. It is the hypothesis that there is a difference between groups.  
  
$HA:At\,least\,one\,P_{i}\,is\,different.$.  
That is, **NOT** all probabilities are equal. We don't define the alternative hypothesis more specifically than that. 
  
To calculate the Chi-Square ($\chi^{2}$) statistic, for each category, we subtract the expected counts from the observed counts, square that value, and divide by the expected counts. We then sum the results for each category.
  
Below is the calculation in R. 
  
```{r}  
# Calculating chi square statistic
chi_stat_gof <- sum((freq_table_poly-expected)^2/expected)
chi_stat_gof
```
  
Our $\chi^{2}$ statistic is `r chi_stat_gof`, which doesn't necessarily tell us what we want to know. BUT, we can use this statistic to calculate our **p-value**.  
  
P-values are a **very** controversial topic in statistics these days. They are often misinterpreted. A p-value tells us **the probability we would have observed these data (or data more extreme) if the null hypothesis were true**. Note that the p-value does **NOT** tell you the probability the null hypothesis is true. 
  
We can get the p-value for our test using the `pchisq()` function. It requires a few arguments - `q` - the quantile (our $\chi^{2}$ statistic) and `df` - the degrees of freedom (the number of groups minus 1). We also need to tell R that `lower.tail=FALSE`. For reasons beyond the scope of this tutorial, the $\chi^{2}$ distribution is one-sided, so we need to change this argument to `FALSE`.  
  
```{r}
# using pchisq() to get p value for the chi square statistic
# 3 groups (R, D, I) minus 1 = 2 degrees of freedom
p_value_pol <- pchisq(chi_stat_gof, df=2, lower.tail = FALSE)
p_value_pol
```
  
It looks like our p-value is very small, indicating that it's very unlikely we would have observed the frequencies we did if the null were true. It's commonplace to reject the null hypothesis whenever our p value is less than .05. We will reject the null in this case, but beware: **Null Hypothesis Significance Testing  is often misused/misinterpreted** (see the end of the tutorial). Again, remember that our p-value is **NOT** the probability the null is true. Rather, it is **the probability we would have observed the data if the null were true**.  

Finally, there's actually an easier way to perform the test in R. We can simply give our frequency table (`freq_table_poly`) to the `chisq.test()` function.  
  
```{r}
# Use the chisq.test() function to do the work for us
chisq.test(freq_table_poly)
```
  
The results are the same as above, though the above calculation was done to facilitate conceptual understanding of the material.  

### **Exercise 2**

Using the dataset `mtcars`, perform a chi-square Goodness of Fit test on the frequency table computed in exercise 1.
  
```{r}
# Re-calculating the frequency table, tidyverse method
freq_tab <- mtcars %>%
  select(vs) %>%
  table()
```
  
```{r gof-test, exercise=TRUE}
# Perform goodness of fit test and use the p-value to reject/not reject the null

```

```{r gof-test-solution}
# Perform goodness of fit test and use the p-value to reject/not reject the null
chisq.test(freq_tab)
# Fail to reject the null, as p-value is above .05.
```
  
## **Categorical Data - Multiple variables**
  
It's rare that a researcher is interested in only one variable. Rather, they will be interested in multiple variables. For this example, let's use the `mtcars` - *Motor Trend Car Road Tests*, a dataset that comes pre-loaded in R, containing data about various cars from 1974.
  
```{r echo=F}
# Convert mtcars to tibble for ease of printing
mtcars <- as_tibble(mtcars)
mtcars
```
  
Let's say we're interested in two specific variables - `vs` and `am`. `vs` contains data about the shape of each car engine, where a value of 0 indicates that the engine is V-shaped, while a value of 1 indicates that the engine is straight. `am` contains data about each car's transmission, where a value of 0 indicates an automatic transmission, while a value of 1 indicates a manual transmission.
  
To make the data easier to look at, we are going to recode these values using dplyr. Specifically, we will use `mutate()` and `case_when()`. Note that this will not change the information contained in the data; it will only make it easier to look at.
  
```{r}
# Recoding data - calling the new columns vs_new & am_new
mtcars <- mtcars %>% 
  mutate(
    vs_new=case_when(
      vs==0 ~ "v-shaped",
      vs==1 ~ "straight"
      ),
    am_new=case_when(
      am==0 ~ "automatic",
      am==1 ~ "manual"
    )
  )
# Previewing our new columns
mtcars %>% 
  select(am_new, vs_new)
```
  
### **Contingency Tables**
  
Now that our data are recoded, we can use the `table()` function to tabulate the co-occurence of values between `vs_new` and `am_new`. That is, a *multivariate frequency table* (multivariate simply means what it sounds like: multiple variables). This is also called a cross-tabulation.

Note that the more variables you include, the more difficult a contingency table is to interpret. Typically, contingency tables look at 2 variables, or occasionally 3. A contingency table based on greater than 3 variables will be difficult to interpret (and will likely have small cell counts - see below). 
  
You also usually need to specify the variables you give `table()`.  The original dataset, `mtcars`, has `r ncol(mtcars)` variables. Let's see what happens when we try to run the table function on this dataset without specifying the variables we want to cross-tabulate:
  
```{r error=T}
# Showing what happens when you try to get a contingency table with too many variables
mtcars %>%
  table()
```
  
As you can see, there are too many elements for R to compute cross-tabs on. So you need to specify a finite number of variables.
  
```{r}
# contingency table for mtcars, Base R method
table(mtcars$vs_new, mtcars$am_new)
# contingency table for mtcars, tidyverse method
freq_table_mtcars <- mtcars %>%
  select(vs_new, am_new) %>%
  table()
freq_table_mtcars
```
  
### **Chi-Square Test of Independence**
  
Now that we have our contingency table, we may wonder if there is a relationship between `vs_new` and `am_new`. In other words, is the shape of a car's engine independent from the type of transmission? 
  
It turns out that there is a statistical test we can run to test for this, also using the Chi-Square distribution. The test is called the **Chi-Square Test of Independence**. The test works similarly to the Test of Goodness of Fit. In face, the formula is the same:  
  
$$\chi^{2}=\sum_{i=1}^{N} \frac{(O_{i}-E{i})^{2}}{E_{i}}$$
  
However, the method by which we compute expected frequencies differs slightly. Before we get to that, let's define our null and alternative hypotheses.
  
The null hypothesis for the test of independence is simply that the two  variables of interest are unrelated - i.e., independent.  
  
$H0: Engine\;shape\; and\; transmission\; type\; are\; independent\; of\; one\; another.$  
  
The alternative hypothesis states that the two variables of interested **ARE** related - i.e., not independent.
  
$HA: Engine\;shape\; and\; transmission\; type\; are\;not\; independent\; of\; one\; another.$   
  
The last thing to do before performing the test is define the method by which we calculate expected frequencies.  
  
The formula for expected frequencies for a given cell is the following:
  
$$\frac{RowTotal*ColumnTotal}{TotalCounts}$$  
  
```{r}
# our contingency table
freq_table_mtcars
```
  
We can work through each cell to demonstrate this. Let's work through the first cell, with a `vs_new` value of "straight" and an `am_new` value of "automatic". The row total for this cell is $7+7=14$, and the column total for this cell is $7+12=19$. The total counts is simply the total number of observations in the table, $7+7+12+6=32$. So the expected counts for the first cell is $$\frac{19*14}{32}=8.3125$$.  
  
We could compute the expected frequencies for each cell, but we don't have to. R can do it for us and output the results of the test when we use the `chisq.test()` function. We simply pass the contingency table `freq_table_mtcars` to the function and R knows that we want to perform a chi-square test of independence.
  
```{r}
# using chisq.test() to perform chi square test of independence
chisq.test(freq_table_mtcars)
```
  
The p-value here is `r chisq.test(freq_table_mtcars)$p.value`, indicating a relatively high probability that we would have observed these data (or data more extreme) if the null hypothesis were true. We would fail to reject the null hypothesis here, retaining our belief that engine shape and transmission type are unrelated.
  
#### **Assumptions of the Chi-Square Test**
  
We haven't discussed it yet, but the chi-square test relies on two assumptions that need to be met to have confidence in the results of the test. 
  
1. Sufficiently large expected counts 
  + Each cell needs to have expected counts > 5.
2. Data are independent of one another. 
  
While we have met the assumptions of the test in this case, there will be instances where these assumptions will not be met. In particular, there are times when cell counts will be too small for a chi-square test. In these cases, we can use **Fisher's Exact Test**.
  
### **Fisher's Exact Test**
  
Fisher's Exact Test relies on a different distribution than the chi-square test. The details of this are unimportant here. However, we can still use the Fisher's Exact Test to test the independence of `vs_new` and `am_new` in the `mtcars` dataset. All we need to do is pass the table `freq_table_mtcars` to the R function `fisher.test()`, and we will have a result.
  
```{r}
# use fisher.test() to perform fisher exact test on our frequency table
fisher.test(freq_table_mtcars)
```
  
The results here agree with the results from the chi-square test. The p-value is relatively high, forcing us to fail to reject the null and retain our belief in the independence of these two variables.  
  
## **Some Final Thoughts on NHST**
  
By this point, you've learned about ways to perform statistical tests on categorical data using **Null Hypothesis Significance Testing (NHST)**. There are many critiques of NHST, both in the way it is used in practice and in the core principles behind the logic of NHST. 
  
For example, some researchers may collect more data until their p-value falls below the typical rejection criterion of .05. This practice is known as **p-hacking** and can result in the publication of erroneous results. Others have criticized the .05 criterion as being too liberal and suggest that researchers adopt a more conservative threshold (such as .001). One final critique of NHST in practice comes from researchers misinterpreting the definition of a p-value. A p-value does **NOT** give you the probability the null hypothesis is true. Rather, it gives you the probability of observing your data (or data more extreme) given that the null is true (i.e., $P(Data|Null)$).
  
However, there is an alternative method to statistical testing that can give researchers the probability of the null hypothesis given a set of data ($P(Null|Data)$). This rapidly growing field is known as **Bayesian Statistics**. This is a large topic well beyond the scope of this tutorial, but given a few assumptions, there is a way to get more information out of your data than the traditional NHST method can give you.
  
## **Conclusion & Glossary**

We've now learned how to perform standard statistical tests on categorical data, as well as how to compute frequency tables for one and two-dimensional data. 

### **References**
  
Navarro, D. J. (2015). *Learning Statistics with R: A Tutorial for Psychology Students and Other Beginners*, Version 0.6.   



