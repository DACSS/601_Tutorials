---
title: 'Tutorial 3: Data Wrangling'
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
load("601-DataWrangling.rdata")
tutorial_options(exercise.timelimit = 10)
```

## **Introduction**

In this tutorial, we will begin looking at large datasets and learn how to read them with R. These datasets are pre-loaded and will reappear in future tutorials, so it will be useful to get familiar with their contents.  

We will learn the following R Commands:

* `head()`
* `dim()`
* `colnames()`
* `select()`
* `table()`
* `prop.table()`
* `pivot_longer()`
* `pivot_wider()`

We will be introduced to following datasets:

* Post-Secondary Employment Outcomes: **pseo** 
* Worldwide Access to Electricity: **electricity**
* 2016 American National Election Study: **anes**

## **Reading Data into R**

For this (and other) tutorials, datasets are pre-loaded into R for your use. A major step in any analysis, though, is obviously getting your data into R in the first place. 

To that end, I have posted to our Google Classroom an R script featuring example code and associated packages for loading a number of standard dataset types (Excel files, comma-separated values, tab-delimited files, SPSS files, Stata files, ...). There is additional functionality for reading in JSON, XML, and other file types. If you are having trouble getting data you want into R, let me know!

## **Introducing the Data**

R reads external datasets as objects called dataframes. Dataframes are two-dimensional data structures, or in other words, tables. Think of them as pivot_widersheets like you would find in Microsoft Excel or Google Sheets, consisting of columns and rows. Many R functions, and the most important ones we will learn about in these tutorials, work with dataframes. 

We will preview three datasets that will be used in this tutorial and future tutorials. 

#### Post-Secondary Employment Outcomes

PSEO is a dataset from the U.S. Census Bureau that provides earnings and employment outcomes for college and university graduates by degree level, degree major, post-secondary institution, and years after graduation. The sample consists of graduates from universities in Texas, Colorado, Michigan and Wisconsin. These are up-to-date data from 2018. [Learn more about it here](https://lehd.ces.census.gov/data/pseo_beta.html)

In these data, rows are different years, universities and majors; columns are their characteristics.

The dataset has been pre-loaded with the name: **pseo**. We can use the `head()` function to preview the first five rows of any dataframe, like so:

```{r, echo=TRUE}
#Preview: pseo
head(pseo)
```

Don't worry if you don't understand everything (or anything) from this preview. We will learn how to read the data soon.

#### Worldwide Access to Electricity

This is a dataset from the World Bank and the Sustainable Energy for All Global Tracking Framework. It contains the percentage of the population with access to electricity from every country between 1990 and 2016. [Learn more about it here](https://data.worldbank.org/indicator/EG.ELC.ACCS.ZS?view=chart).

In these data, rows are individual countries and columns are years.

The dataset has been pre-loaded with the name: **electric**. Try using the `head()` function to preview this dataset:

```{r viewelec, exercise=TRUE}
#Preview: electric

```

```{r viewelec-solution}
#Preview: electric
head(electric)
```

You should be able to quickly tell how these data look different than the **pseo** data.

#### 2016 American National Election Study
 
ANES is a dataset collected by the Center for Political Studies of the Institute for Social Research at the University of Michigan. These data contain survey questions asked to a nationally representative sample of Americans following the 2016 Election. [Learn more about it here](https://electionstudies.org/project/2016-time-series-study/).

In these data, rows are individual respondents and columns are questions.

The dataset has been pre-loaded with the name: **anes**. Try using the `head()` function to preview this dataset:

```{r viewanes, exercise=TRUE}
#Preview: anes

```

```{r viewanes-solution}
#Preview: anes
head(anes)
```

If you see a lot of confusing numbers- don't worry- that's how it's supposed to look. The numbers all represent different questions and answers. For example, the first column, **v162002**, represents: "How many programs about the campaign for President did you watch on television?". **1** means "None", **2** means "Just one or two", **3** means "Several", and **4** means "A good many". 

This is how a lot of survey data looks when raw. In our future tutorial on Recoding Variables, we will revisit this dataset to learn how to clean this type of data to be more readable and easy to analyze. For now, just know that this is how it looks.

## **Understanding the Dimensions**

Now it's finally time to start reading our data. R is helpful because we can use it to describe data very quickly without having to manually scan through anything.

First, let's use the function `dim()` to get the dimensions of our data. We will try it with the **electric** data. 

```{r, echo=TRUE}
#Get the dimensions of electric
dim(electric)
```

This returns two values: the number of rows and number of columns. In this case, the **electric** data has 261 rows (there are data for 261 countries) and 29 columns. `Dim()` is useful for quickly getting a sense of the size of the data you're working with. 

Next, we will use the function `colnames()`. This returns the names of every column, which helps us find out what data is contained in a dataset. We will also try this on **electric**, and if all goes well, we should get 29 column names back, according to the dimensions we saw before.

```{r, echo=TRUE}
#Get the col names of electric
colnames(electric)
```

Other than **Country Name** and **Country Code**, all the columns are different years in which access to electricity was measured. If we want to focus on specific columns (which we do) now we know which are available and what their names are.

### Exercise 1

Try finding the dimensions and column names of the **pseo** data as it was done above with **electric**.

```{r dimpseo, exercise=TRUE}
#Find the dimensions of pseo

#Get the col names of pseo

```

```{r dimpseo-solution}
#Find the dimensions of pseo
dim(pseo)
#Get the col names of pseo
colnames(pseo)
```

## **Select Basics**

If we want to examine specific columns, we can use the `select()` function. This is an important function that we will use again and again with R. 

`Select()` follows the following format: `select(data, column)`. Columns can be specified either by name or by number (this is why it's helpful to use `colnames` beforehand). See the following example using the **electric** data and its **Country Name** column. **Country Name** is the first column, so we can also refer to it as **1**.

```{r, echo=TRUE}
#Select Country Name out of electric
select(electric, "Country Name")
#Select Country Name out of electric (same output)
select(electric, 1)
```

You need quotes around the column name if it contains spaces or is a number (which applies to all the columns in **electric**). R treats numbers and spaces differently than letters- the quotes let it know to read the name as a name regardless of what's inside. If the column name is just a word, like **state**, don't worry about quotation marks.

We can also select multiple columns at once. The first way is with the format: `select(data, column1, column2)`. Below is an example of selecting both the **Country Name** and **2016** columns out of the **electric** data. 

```{r, echo=TRUE}
#Select Country Name and 2016 out of electric
select(electric, "Country Name", "2016")
```

The result should show why the select function is useful. It allows you to examine specific columns side by side, which in the case of **electric**, allows us to clearly see the percentage of the population in each country that had access to electricity in 2016. You can use this function to view as many columns as you want with the format: `select(data, column1, column2, column3, column4)`.

There is one more useful shortcut that you should be aware of when using `select()`. In many functions, you can use `:` to group a bunch of adjacent variables together, in the format `select(data, columnX:columnY)`. Basically, `:` means "between". See the following example:

```{r, echo=TRUE}
#Select the columns betwen 2010 and 2016 from electric
select(electric, 23:29)
```

You can also combine these different methods when using `select()`. Below, we select the **Country Name** column, the **1990** column, and the **2014**, **2015**, and **2016** columns. 

```{r, echo=TRUE}
#Select Country Name, 1990, 2014, 2015, and 2016 from electric
select(electric, "Country Name", "1990", "2014":"2016")
```

### Exercise 2

Use the `select()` function with the **pseo** data to select the **institution_name**, **deglevl**, and **ciptitle** columns. Use `colnames` if you want to check the column numbers and names.

```{r selectpseo, exercise=TRUE}
#Select institution_name, deglevl, and ciptitle from pseo

```

```{r selectpseo-solution}
#Select institution_name, deglevl, and ciptitle from pseo
select(pseo, institution_name, deglevl, ciptitle)
#or...
select(pseo, 2, 4, 6)
```

#### A note:

There are many ways to accomplish the same things in R. The `select()` function in this tutorial and other functions in upcoming tutorials are part of the **tidyverse** package, which is a cutting-edge set of functions that simplify the process of data analysis, especially with large and complex projects. Know that you are learning the most modern and most efficient version of R, but be aware that other methods exist. 

## **Useful Select Functions**

There are a few useful functions that can be used within `select()` that can make the process of finding specific columns much easier. In this tutorial, we will focus on `starts_with()`, `ends_with()`, and `contains()`. All are used when you do not know the exact names or numbers of specific columns- which is especially useful when selecting multiple columns at once in very large datasets.

First is `starts_with()`. This is used inside of `select()` to choose columns whose names start with certain characters. In the example below, we select all of the years in **electric** which begin with "201", which returns the years 2010 through 2016.  

```{r, echo=TRUE}
select(electric, starts_with("201"))
```

This is evidently more efficient than manually naming those seven columns. Also, notice how there are two closing parantheses at the end to balance the two opening parantheses used. 

Next, is `ends_with()`. Unsurprisingly, this does the same thing, but selects the columns which end with certain characters. In the example below, we select the columns in **pseo** which end with "earnings".

```{r, echo=TRUE}
select(pseo, ends_with("earnings"))
```

This returns the columns **p25_earnings**, **p50_earnings**, and **p75_earnings**.

Finally, `contains()`. This is a less restrictive version of the other two functions, selecting column names that contain certain characters regardless of where they reside in the name. If for some reason you wanted only to examine years in **electric** that contain the number "7", you could do the following:

```{r, echo=TRUE}
select(electric, contains("7"))
```

Super cool.

Whether you need to use `starts_with()`, `ends_with()`, or `contains()` will depend on what the column names of your data look like. You may not need to use them at all, but they are useful to know.

## **Working with Columns**

We now know how to use `select()` by itself to look at columns of dataframes. However, we can also combine `select()` with other commands in order to look closely at columns of data. 

#### Previewing Columns

So far, whenever we have used `select()`, the output has been all of the values for the columns we specify. However, we can preview the first five rows of specified columns with `head()` like we previewed entire datasets earlier. Use the format: `head(select(data, column))`. 

In the following, the **deglevl** column of **pseo** is previewed:

```{r, echo=TRUE}
#Preview deglevl
head(select(pseo, deglevl))
```

#### Naming Columns

Here's a shortcut. We can use `<-` to assign a name to specific columns in the same way we renamed data in our last tutorial. Then we can directly refer to a column instead of needing to use `select()` inside of functions. 

In the following, we will rename **deglevl** as **Degree** and then preview **Degree**. The output will be identical to the last example.

```{r, echo=TRUE}
#Rename deglevl to Degree
Degree <- select(pseo, deglevl)
#Preview Degree
head(Degree)
```

#### Creating Tables

The `table()` function is used to quickly assess the distribution of values within a column. This a very practical function and the output is easy to understand.

In the following, we will make a table of **Degree**.   

```{r, echo=TRUE}
#Make a table of Degree
table(Degree)
```

Just to clarify, the code `table(select(pseo, deglevl))` would have given the same output.

As you can see, `table()` allows us to collapse all the values of a huge column into a compact form that's easy to read. In this example, we can quickly get a sense of the sample used for research in the **pseo** data. 

#### Creating Proportional Tables

Next, we will learn how to create proportional tables with `prop.table()`. Instead of returning the number of occurrences of each value, proportional tables return the *proportion* that each value occurs. The example below creates a proportional table for the Degree Level column of the **pseo** data.

```{r, echo=TRUE}
#Create a prop.table for deglevl in pseo
prop.table(table(Degree))
```

Notice that `table()` is used within `prop.table()`. `Prop.table()` is not used on the data directly (because it only works with numeric data, such as a table). 

Also notice that the output of `prop.table()` is a list of proportions in decimal form. These are percentages. In **pseo**, 0.5277, or 52.77% of respondents have a Baccalaurate (Bachelor's) degree. 

This is our first entry into descriptive statistics. Proportional tables are very useful for making quantitative conclusions about nominal data. The ability to find percentages of data with certain characteristics is very practical in the social sciences.

### Exercise 3

Either by using `select()` within `table()` or by first renaming the column with `<-`, make a table for the **institution_name** column of **pseo**. Then, create a proportional table of the same column.

```{r partone, exercise=TRUE}
#Make a table for institution_name

#Make a proportional table for institution_name

```

```{r partone-solution}
#Make a table for institution_name
table(select(pseo, institution_name))
##Or...
Schools <- select(pseo, institution_name)
table(Schools)
#Make a proportional table for institution_name
prop.table(table(select(pseo, institution_name)))
##Or...
Schools <- select(pseo, institution_name)
prop.table(table(Schools))
```

## **Tidy Data**
 
We have worked with data as they were formatted by the original dataset authors. However, as we can recall from class, one of our objectives in any analysis is to have tidy data. The idea is that:

1. Each variable has it's own column.
1. Each observation has it's own row.
1. Each value has it's own cell. 

As we look to tidy our data, two functions are likely to help: `pivot_longer()` and `pivot_wider()`.

## **Intro: pivot_longer and pivot_wider**

The point of data wrangling is to turn messy data into tidy data. But what exactly does it mean for data to be *messy* or *tidy*? As mentioned in the introduction, data is tidy when individual rows represent observances, individual columns represent variables, and individual cells represent values. 

The **electric** and **pseo** datasets we have been using are fairly complex datasets - with multiple entries for each school in pseo and multiple columns for each annual country measure in electric. Until now, we have just been working around or ignoring their complexity and not trying to reshape the data to isolate the specific combination of data points we are interested in. Now, we will learn to use the two most useful data wrangling functions, `pivot_longer()` and `pivot_wider()`, to reorganize them. These functions convert columns into new rows (pivot_longer) and condense rows into new columns (pivot_wider).

## **pivot_longer: Basics**

Let's start with `pivot_longer()` and **electric**. `pivot_longer()` collapses multiple columns into one column; where the original column names become row values. It is used when you notice that you have columns that are not variables. `pivot_longer()` makes "wide" data "taller". For example, in **electric**, the columns represent years. While time is certainly a variable, the primary variable being measured in **electric** is electricity access. Different years are, more accurately, different observances of that variable. We can use `pivot_longer()` to reshape the data to fit accordingly.

As a reminder, here is what we know about **electric** before wrangling. There are 261 country cases, each identied by a country name and country code. Each country has 27 years (1990-2016) where the variable `year` indicates the proportion of the population with access to electricity during that year.

```{r, echo=TRUE}
str(electric)
```

Now we will use `pivot_longer()` to reshape the data into country-year cases. The goal is to create a new dataset with 4 columns (country name, country code, year, and access) and 261x27=7,047 rows.

The `pivot_longer()` function follows the following format: `pivot_longer(data, columns, names_to = "new column name", value = "value")`. The **names_to** refers to the new column that will contain the old column names. In the case of **electric**, the names_to is **year**. The **values_to** refers to the new column that will contain the data that used to be found in rows. In the case of **electric**, the values_to is **access** (to electricity). When using this formula, you can refer to a single column, a list of columns, or as shown in the next example, a range of columns using `:`. However, it is usually best to pivot_longer *all* of the columns of data available (otherwise, your data will be left in a half-messy, half-tidy state, which is probably worse than before). Below, all of the years of **electric** are pivot_longered into a **year** column and an **access** column.

```{r, echo=TRUE}
pivot_longer(electric, `1990`:`2016`, names_to = "year", values_to = "access")
```

The purpose of `pivot_longer()` should now be evident. The mostly horizontal original data has been converted into mostly vertical data. 

One trade-off is that it is now much harder to look at the progression of individual countries since they are no longer represented by single rows. Fear not- this issue can be easily solved with either `filter()` or `arrange()`, two functions we will learn later on.

## **pivot_wider**

`pivot_wider()` is the opposite of `pivot_longer()`. It is used when you have rows that represent variables, not different observances. `pivot_wider()` converts the different values of rows into new columns, making "tall" data "wider". In **pseo**, there are many examples of rows like this, like **year_postgrad**, which we have had to deal with in prior tutorials. **Year_postgrad** is measured in rows (with a value of either 1, 5, or 10), but it is really a variable. We can use `pivot_wider()` to pivot_wider earnings data across new columns for different years post-graduation.

For reference, this is what **pseo** looks like before wrangling:

```{r, echo=TRUE}
pseo
```

`pivot_wider()` follows the format: `pivot_wider(data, names_from, values_from)`. The **names_from** is the original column whose values will become new column names, which in this case is **year_postgrad**. The **values_from** is the column whose information will become the values in the new columns, which in the example below, is **p50_earnings**. Below, the values of median earnings in **pseo** are pivot_wider across new columns for years post-graduation.

```{r, echo=TRUE}
pivot_wider(pseo, names_from=year_postgrad, values_from=p50_earnings)
```

The new columns are listed at the very end, so you will have to scroll to the right to see them. Three new year columns (**1**, **5**, and **10**) have now replaced the old columns **year_postgrad** and **p50_earnings**. It is now possible to view the median earnings for a certain number of years after graduation as a column, not as a subset of rows. 

Why is this useful? In the example below, we pipe `pivot_wider()`, `select()`, and `summarize_all()` to find the mean income of the entire dataset for different years after graduation. We'll come back to the piping operator and `Summarize_all()` later on. 
  
We also use `mutate(row=row_number())` to give each row a unique identifying value.  

```{r, echo=TRUE}
pseo %>%
  mutate(row=row_number()) %>%
  pivot_wider(names_from=year_postgrad, values_from=p50_earnings)%>%
  select(`1`, `5`, `10`) %>%
  summarize_all(mean, na.rm = TRUE)
```

With `pivot_longer()` and `pivot_wider()`, you now know the fundamentals of reshaping data. It is largely up to you to decide when you need to use these functions and if they will be helpful. When confronted with a large dataset, rearranging data to be easy to analyze is very important. Like always, there are many methods to do the same things in R, but these functions are useful options to have. 

### **pivot_wider: Advanced**

pivot_wider can be used to manipulate a dataset and save it as a new one for analysis, but much like pivot_longer, it is often used as a part of a piped set of consecutive commands to wrangle the data into the desired format and with the desired summary statistics or other information.

## **Conclusion & Glossary**

You now know how to look at the size of datasets, select specific columns, and examine their contents. You have also begun to manipulate your datasets, and get them into tidy data format. 

Coming up in the next tutorial...we will start to visualize our data. 

#### Function Glossary

Here's a recap of the functions you have encountered so far:

**Tutorial 1: R Basics and Assigning Variables**

* Basic mathematics: `+`,`-`,`*`,`/`
* Logical operators: `==`,`>`,`<`,`>=`,`>=`
* Assign name: `<-`
* Create vector: `c()`

**Tutorial 2: Reading and Describing Data**

* Preview data: `head()`
* Get dimensions: `dim()`
* Get column names and numbers: `colnames()`
* Select specific columns: `select()`
 + `starts_with()`
 + `ends_with()`
 + `contains()`
* Get values of column: `table()`
* Get proportions of values of column: `prop.table()`
* Tidy data: `pivot_longer()` and `pivot_wider()`

